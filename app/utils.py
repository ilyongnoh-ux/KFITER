"""
[íŠ¹í—ˆ ì²­êµ¬í•­ 2: ë°ì´í„° ì²˜ë¦¬ ì¥ì¹˜]
KFIT Smart ETL (Extract, Transform, Load) Engine
ë°œëª…ì˜ ëª…ì¹­: "ë¹„ì •í˜• ì—‘ì…€ ë°ì´í„°ì˜ ìë™ ì •ê·œí™” ë° ë§ˆìŠ¤í‚¹ ë°ì´í„°ì˜ ì •ë°€ ëŒ€ì¡° ì¥ì¹˜"

[ê¸°ìˆ ì  íŠ¹ì§•]
1. Fuzzy Matching: ë‹¤ì–‘í•œ ë™ì˜ì–´(Synonyms) ì‚¬ì „ì„ í†µí•œ ì»¬ëŸ¼ ìë™ ë§¤í•‘.
2. Context Awareness: 'ê³„ì•½ì'ì™€ 'í”¼ë³´í—˜ì' í‚¤ì›Œë“œë¥¼ ë¶„ì„í•˜ì—¬ ë°ì´í„°ì˜ ì£¼ì²´ ì‹ë³„.
3. Privacy Preserving: ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸ì—ì„œ ìƒë…„ì›”ì¼/ì„±ë³„ë§Œ ì¶”ì¶œí•˜ê³  ì›ë³¸ì€ ì¦‰ì‹œ íŒŒê¸°.
4. Dual Verification: í•´ì‹œ í‚¤ì™€ ì´ë¦„ íŒ¨í„´ ë§¤ì¹­ì„ ê²°í•©í•˜ì—¬ ë™ëª…ì´ì¸ ë° ê°€ì¡± ì‹ë³„.
"""

import streamlit as st
import pandas as pd
import re
import json
from datetime import datetime
import os


# ---------------------------------------------------------
# [ë°ì´í„°(dbí¬í•¨) ì˜¤ë¥˜] ê³„ì•½ì(ê°œì¸/ë²•ì¸) ë¶„ê¸° ì§€ì› ìœ í‹¸
# - ê³ ê°ê´€ë¦¬ ì£¼ì²´(ì‚¬ëŒ)ì™€ ê³„ì•½ì(ë²•ì¸/ê°œì¸)ê°€ ë¶„ë¦¬ë˜ëŠ” í˜„ì‹¤ ë°ì´í„°ë¥¼ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ ìµœì†Œ í•¨ìˆ˜
# - íŠ¹í—ˆ ëª…ì„¸ì„œ ê´€ì : "ì—­í• (Role) ê¸°ë°˜ ë°ì´í„° ì²˜ë¦¬"ì—ì„œ 'ê³„ì•½ì ìœ í˜• íŒì •'ê³¼ 'ì •ê·œí™” í‚¤ ìƒì„±'ì€
#   í›„ì† ë‹¨ê³„(ë§¤ì¹­/ê²€ìƒ‰/ê·¸ë£¹í•‘)ì˜ ì˜¤ì°¨ë¥¼ ì¤„ì´ëŠ” í•µì‹¬ ì „ì²˜ë¦¬ ì¥ì¹˜ë¡œ ì„¤ëª… ê°€ëŠ¥
# ---------------------------------------------------------
def is_corporate_name(name: str) -> bool:
    """ê³„ì•½ìëª…ì´ ë²•ì¸/ë‹¨ì²´ë¡œ ë³´ì´ëŠ”ì§€ íœ´ë¦¬ìŠ¤í‹± íŒì •.
    - ëª©ì : UI/DB ë¡œì§ì—ì„œ 'ê³„ì•½ì=ë²•ì¸' ì¼€ì´ìŠ¤ë¥¼ ë¹ ë¥´ê²Œ ë¶„ê¸°í•˜ê¸° ìœ„í•¨.
    - ì£¼ì˜: 100% ì™„ë²½í•œ íŒì •ì´ ì•„ë‹ˆë¼, 'ë²•ì¸ìœ¼ë¡œ ì¶”ì •'ì— ì´ˆì ì„ ë‘” ë³´ìˆ˜ì  ê·œì¹™.
    """
    n = (name or "").strip()
    if not n:
        return False
    corp_kws = [
        "(ì£¼)", "ãˆœ", "ì£¼ì‹íšŒì‚¬", "ìœ í•œíšŒì‚¬", "ì¬ë‹¨", "ì‚¬ë‹¨", "í˜‘ë™ì¡°í•©",
        "ë²•ë¬´ë²•ì¸", "ì„¸ë¬´ë²•ì¸", "íšŒê³„ë²•ì¸", "ë³‘ì›", "ì˜ì›", "í•™êµ", "í•™ì›",
        "ì„¼í„°", "í˜‘íšŒ", "ì¡°í•©", "ê³µì‚¬", "ê³µë‹¨", "ì²­", "êµ¬ì²­", "ì‹œì²­",
    ]
    # í‚¤ì›Œë“œ í¬í•¨ ì‹œ ë²•ì¸ìœ¼ë¡œ íŒë‹¨
    if any(k in n for k in corp_kws):
        return True
    # ê´„í˜¸ ì•ˆì— (ì£¼) ê°™ì€ í‘œê¸°/ì˜ë¬¸ Corp/Ltd ë“±ë„ ë²•ì¸ìœ¼ë¡œ ë³¸ë‹¤
    if re.search(r"\b(CORP|CORPORATION|LTD|LIMITED|INC)\b", n, flags=re.I):
        return True
    return False


def normalize_org_name(name: str) -> str:
    """ë²•ì¸ëª…/ë‹¨ì²´ëª… ì •ê·œí™” í‚¤ ìƒì„±.
    ì˜ˆ) '(ì£¼)ì„ ê²½ìŠ¤í‹¸' / 'ãˆœì„ ê²½ìŠ¤í‹¸' / 'ì£¼ì‹íšŒì‚¬ ì„ ê²½ìŠ¤í‹¸' â†’ 'ì„ ê²½ìŠ¤í‹¸'
    """
    n = (name or "").strip()
    if not n:
        return ""
    # ê³µë°± ì œê±°(ê²€ìƒ‰ í‚¤ëŠ” ë¶™ì—¬ì„œ)
    n2 = n.replace(" ", "")
    # ëŒ€í‘œì ì¸ ë²•ì¸ í‘œê¸° ì œê±°
    for k in ["(ì£¼)", "ãˆœ", "ì£¼ì‹íšŒì‚¬", "ìœ í•œíšŒì‚¬", "ì¬ë‹¨ë²•ì¸", "ì‚¬ë‹¨ë²•ì¸"]:
        n2 = n2.replace(k, "")
    # ê´„í˜¸/ëŒ€ê´„í˜¸ ë“± ì œê±°
    n2 = re.sub(r"[\(\)\[\]\{\}]", "", n2)
    return n2


def _get_base64_image(file_path):
    """(ë‚´ë¶€ìš©) ì´ë¯¸ì§€ë¥¼ Base64ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜"""
    try:
        # íŒŒì¼ì´ ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        if not os.path.exists(file_path):
            # íŒŒì¼ì´ ì—†ìœ¼ë©´ ê²½ê³  í›„ ì¢…ë£Œ (ë˜ëŠ” ê¸°ë³¸ ì•„ì´ì½˜ ì‚¬ìš© ë¡œì§ ì¶”ê°€ ê°€ëŠ¥)
            print(f"âš ï¸ ê²½ê³ : '{file_path}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
            
        with open(file_path, "rb") as f:
            data = f.read()
        encoded_string = base64.b64encode(data).decode()
        return f"data:image/png;base64,{encoded_string}"
    except Exception as e:
        print(f"ì´ë¯¸ì§€ ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

def set_global_page_config(page_title="í•œêµ­ê¸ˆìœµíˆ¬ìê¸°ìˆ ", icon_path="logo.png"):
    """
    ëª¨ë“  í˜ì´ì§€ì—ì„œ ê³µí†µìœ¼ë¡œ ì‚¬ìš©í•  í˜ì´ì§€ ì„¤ì • í•¨ìˆ˜
    :param page_title: í˜ì´ì§€ ì œëª© (ê¸°ë³¸ê°’ ì„¤ì •ë¨)
    :param icon_path: ì•„ì´ì½˜ íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸ê°’: ci.png)
    """
    
    # 1. ì•„ì´ì½˜ ì´ë¯¸ì§€ ë¡œë“œ ë° ë³€í™˜
    icon_data = _get_base64_image(icon_path)
    
    # ì´ë¯¸ì§€ê°€ ë³€í™˜ë˜ì§€ ì•Šì•˜ìœ¼ë©´(íŒŒì¼ ì—†ìŒ ë“±) ê¸°ë³¸ ì´ëª¨ì§€ ì‚¬ìš©
    final_icon = icon_data if icon_data else "ğŸ’°" 

    # 2. set_page_config ì‹¤í–‰
    st.set_page_config(
        page_title=page_title,
        page_icon=final_icon,
        layout="wide",
        initial_sidebar_state="collapsed"
    )

# ---------------------------------------------------------
# 0. App Config (ë¡œì»¬ JSON ì„¤ì • íŒŒì¼)
# ---------------------------------------------------------
APP_DATA_DIR = os.path.join(os.path.expanduser("~"), "KFIT_Data")
APP_CONFIG_PATH = os.path.join(APP_DATA_DIR, "kfit_config.json")

def load_app_config() -> dict:
    """ë¡œì»¬ ì„¤ì • ë¡œë“œ (ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ìƒì„±)"""
    os.makedirs(APP_DATA_DIR, exist_ok=True)
    default = {
        "gcal_enabled": False,
        "gcal_calendar_id": "primary",
        # ì™„ë£Œ ì²˜ë¦¬: "prefix" (ì œëª© ì• âœ…) / "delete" (ì´ë²¤íŠ¸ ì‚­ì œ)
        "gcal_done_action": "prefix",
        # ì˜¤ë¥¸ìª½ 3ì—´ì— ë„ìš¸ ìº˜ë¦°ë” ì„ë² ë“œ URL(agenda/week ë“±)
        "gcal_embed_url": "",
        # ê¸°ë³¸ íƒ€ì„ì¡´
        "gcal_timezone": "Asia/Seoul",
    }
    try:
        if os.path.exists(APP_CONFIG_PATH):
            with open(APP_CONFIG_PATH, "r", encoding="utf-8") as f:
                data = json.load(f) or {}
            default.update({k: v for k, v in data.items() if v is not None})
        else:
            with open(APP_CONFIG_PATH, "w", encoding="utf-8") as f:
                json.dump(default, f, ensure_ascii=False, indent=2)
    except Exception:
        # ì„¤ì • íŒŒì¼ì´ ê¹¨ì ¸ë„ ì•±ì€ ì‚´ì•„ì•¼ í•¨
        pass
    return default

def save_app_config(cfg: dict) -> bool:
    """ë¡œì»¬ ì„¤ì • ì €ì¥"""
    try:
        os.makedirs(APP_DATA_DIR, exist_ok=True)
        with open(APP_CONFIG_PATH, "w", encoding="utf-8") as f:
            json.dump(cfg, f, ensure_ascii=False, indent=2)
        return True
    except Exception:
        return False


# ---------------------------------------------------------
# 1. UI Helpers (ê¸°ì¡´ ìœ ì§€)
# ---------------------------------------------------------
def apply_custom_css():
    st.markdown("""
        <style>
        header {visibility: hidden;}
        #MainMenu {visibility: hidden;}
        footer {visibility: hidden;}
        .block-container {padding-top: 1.5rem !important; padding-bottom: 2rem !important;}
        .kpi-card {
            background-color: white; padding: 20px; border-radius: 10px;
            box-shadow: 0 4px 6px rgba(0,0,0,0.05); border-left: 5px solid #1E3D59;
            text-align: center; transition: transform 0.2s;
        }
        .kpi-card:hover {transform: translateY(-5px); box-shadow: 0 8px 12px rgba(0,0,0,0.1);}
        .kpi-title {font-size: 14px; color: #666; margin-bottom: 5px; font-weight: 600;}
        .kpi-value {font-size: 28px; font-weight: bold; color: #333;}
        .kpi-icon {font-size: 24px; margin-bottom: 10px;}
        [data-testid="stSidebar"] {border-right: 1px solid #E0E0E0;}
        div.stButton > button {border-radius: 6px; height: 3em;}
        </style>
    """, unsafe_allow_html=True)

def metric_card(icon, title, value, col_obj):
    with col_obj:
        st.markdown(f"""
            <div class="kpi-card">
                <div class="kpi-icon">{icon}</div>
                <div class="kpi-title">{title}</div>
                <div class="kpi-value">{value}</div>
            </div>
        """, unsafe_allow_html=True)

def sidebar_logo():
    st.sidebar.markdown("""
        <div style="text-align: center; margin-bottom: 30px; margin-top: 10px;">
            <div style="background: linear-gradient(135deg, #1E3D59 0%, #2B5876 100%);
                color: white; padding: 15px; border-radius: 8px; box-shadow: 0 4px 6px rgba(0,0,0,0.2);">
                <div style="font-size: 22px; font-weight: 800; letter-spacing: 1px;">ğŸ›¡ï¸ KFITer</div>
                <div style="font-size: 11px; font-weight: 400; opacity: 0.9; margin-top: 5px;">Insurance CRM Pro</div>
            </div>
            <div style="color: #666; font-size: 10px; margin-top: 5px; text-align: right;">by WannabeDream</div>
        </div>
    """, unsafe_allow_html=True)

def check_upcoming_birthdays(df, days_lookahead=7):
    """ìƒì¼ ì„ë°•ì ê³„ì‚° ì•Œê³ ë¦¬ì¦˜ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)"""
    if df.empty: return pd.DataFrame()
    today = datetime.now().date()
    current_year = today.year
    upcoming_list = []

    for index, row in df.iterrows():
        try:
            birth_val = row.get('birth_date')
            if not birth_val or pd.isna(birth_val): continue
            
            birth_str = str(birth_val).replace('-', '').replace('.', '').replace('/', '').strip()[:8]
            if len(birth_str) != 8: continue
            
            birth_date = datetime.strptime(birth_str, "%Y%m%d").date()
            try: this_year_bday = birth_date.replace(year=current_year)
            except ValueError: this_year_bday = birth_date.replace(year=current_year, day=28)
            
            if this_year_bday < today:
                try: next_bday = birth_date.replace(year=current_year + 1)
                except: next_bday = birth_date.replace(year=current_year + 1, day=28)
            else: next_bday = this_year_bday
            
            delta = (next_bday - today).days
            if 0 <= delta <= days_lookahead:
                item = row.to_dict()
                item['d_day'] = delta
                item['next_bday'] = next_bday.strftime("%Y-%m-%d")
                upcoming_list.append(item)
        except: continue

    if not upcoming_list: return pd.DataFrame()
    return pd.DataFrame(upcoming_list).sort_values(by='d_day')


# ---------------------------------------------------------
# 2. Smart ETL Engine (í•µì‹¬ ë°œëª…í’ˆ)
# ---------------------------------------------------------
class KFITSmartETL:
    def __init__(self):
        """
        [ì§€ì‹ ë² ì´ìŠ¤ ì´ˆê¸°í™”]
        í˜„ì—…ì—ì„œ ì‚¬ìš©ë˜ëŠ” ë‹¤ì–‘í•œ ìš©ì–´ë“¤ì„ í‘œì¤€ ìŠ¤í‚¤ë§ˆì— ë§¤í•‘í•˜ê¸° ìœ„í•œ ì‚¬ì „ ì •ì˜.
        """
        self.identity_map = {
            'contractor_name': ['ê³„ì•½ì', 'ê°€ì…ì', 'contractor'], # ìš°ì„ ìˆœìœ„ ë†’ìŒ
            'common_name': ['ê³ ê°ëª…', 'ì„±ëª…', 'ì´ë¦„', 'name', 'customer'],
            'contractor_phone': ['ê³„ì•½ìì—°ë½ì²˜', 'ê³„ì•½ìíœ´ëŒ€í°', 'ê³„ì•½ìíœ´ëŒ€ì „í™”', 'ê³„ì•½ìì „í™”ë²ˆí˜¸'],
            'common_phone': ['ì—°ë½ì²˜', 'íœ´ëŒ€í°', 'ì „í™”ë²ˆí˜¸', 'í•¸ë“œí°', 'ëª¨ë°”ì¼', 'hp', 'mobile', 'íœ´ëŒ€ì „í™”', 'íœ´ëŒ€í°ë²ˆí˜¸'],
            'rrn': ['ì£¼ë¯¼ë²ˆí˜¸', 'ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸', 'rrn'],
            'birth_date': ['ìƒë…„ì›”ì¼', 'ìƒì¼', 'birth'],
            'gender': ['ì„±ë³„', 'ë‚¨ì—¬', 'gender'],
            'region': ['ì£¼ì†Œ', 'ê±°ì£¼ì§€', 'ì‹œë„', 'address'],
            'email': ['ì´ë©”ì¼', 'ë©”ì¼', 'email','e-mail']
        }
        self.financial_map = {
            'insured_name': ['í”¼ë³´í—˜ì', 'ëŒ€ìƒì', 'insured'], # [ì¤‘ìš”] í”¼ë³´í—˜ì ì‹ë³„ í‚¤ì›Œë“œ
            'insured_phone': ['í”¼ë³´í—˜ìì—°ë½ì²˜', 'í”¼ë³´í—˜ìíœ´ëŒ€í°', 'í”¼ë³´í—˜ìíœ´ëŒ€ì „í™”', 'í”¼ë³´í—˜ìì „í™”ë²ˆí˜¸', 'í”¼ë³´í—˜ìí•¸ë“œí°', 'í”¼ë³´í—˜ìëª¨ë°”ì¼'],
            'insured_rrn': ['í”¼ë³´í—˜ìì£¼ë¯¼ë²ˆí˜¸', 'í”¼ë³´í—˜ì ì£¼ë¯¼ë²ˆí˜¸', 'í”¼ë³´í—˜ìì£¼ë¯¼ë“±ë¡ë²ˆí˜¸', 'í”¼ë³´í—˜ì ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸'],
            'company': ['ë³´í—˜ì‚¬', 'íšŒì‚¬', 'company', 'ë³´í—˜íšŒì‚¬'],
            'product_name': ['ìƒí’ˆ', 'ë³´í—˜ëª…', 'product', 'ìƒí’ˆëª…', 'ë³´í—˜ìƒí’ˆ', 'ë³´í—˜ìƒí’ˆëª…', 'ë³´ì¥ëª…', 'ë‹´ë³´ëª…'],
            'policy_no': ['ì¦ê¶Œë²ˆí˜¸', 'ì¦ê¶Œ', 'ì¦ì„œë²ˆí˜¸', 'ì¦ë²ˆí˜¸', 'ê³„ì•½ë²ˆí˜¸', 'í´ë¦¬ì‹œë²ˆí˜¸', 'policy_no'],
            'premium': ['ë³´í—˜ë£Œ', 'ë‚©ì…', 'premium', 'ì›”ë³´í—˜ë£Œ', 'ë³´í—˜ë£Œ(ì›”)', 'ë‚©ì…ë³´í—˜ë£Œ'],
            'status': ['ìƒíƒœ', 'ìœ ì§€', 'status', 'ê³„ì•½ìƒíƒœ'],
            'start_date': ['ê³„ì•½ì¼', 'ê°€ì…ì¼', 'ì‹œì‘', 'ì²­ì•½', 'ì²­ì•½ì¼', 'ê°œì‹œì¼', 'ë³´í—˜ì‹œì‘ì¼', 'ê³„ì•½ê°œì‹œì¼'],
            'end_date': ['ë§Œê¸°', 'ì¢…ë£Œ', 'end', 'ë§Œê¸°ì¼', 'í•´ì§€ì¼', 'ì¢…ë£Œì¼']
        }

    def _clean_text(self, text):
        """[ì „ì²˜ë¦¬] íŠ¹ìˆ˜ë¬¸ì ì œê±° ë° ì†Œë¬¸ì ë³€í™˜ìœ¼ë¡œ ë§¤ì¹­ ì •í™•ë„ í–¥ìƒ"""
        return re.sub(r'[^ê°€-í£a-zA-Z0-9]', '', str(text)).lower()

    def _normalize_header(self, columns):
        """
        [ì•Œê³ ë¦¬ì¦˜: ë¬¸ë§¥ ì¸ì‹ í—¤ë” ë§¤í•‘]
        ë‹¨ìˆœ ì¼ì¹˜ê°€ ì•„ë‹Œ 'í¬í•¨ ê´€ê³„'ì™€ 'ìš°ì„ ìˆœìœ„'ë¥¼ ê³ ë ¤í•˜ì—¬ ì»¬ëŸ¼ì˜ ì˜ë¯¸ë¥¼ ì¶”ë¡ í•¨.
        ì˜ˆ: 'í”¼ë³´í—˜ì ì„±ëª…' -> 'insured_name'ìœ¼ë¡œ ë§¤í•‘ (ì¼ë°˜ 'ì„±ëª…'ë³´ë‹¤ ìš°ì„ ê¶Œ ê°€ì§)
        """
        mapping = {}
        full_schema = {**self.identity_map, **self.financial_map}
        
        for user_col in columns:
            clean = self._clean_text(user_col)
            best_match = None
            
            # [Step 1] í”¼ë³´í—˜ì(Insured) ê´€ë ¨ í‚¤ì›Œë“œ ìš°ì„  ê²€ì‚¬
            if 'í”¼ë³´í—˜ì' in clean or 'insured' in clean:
                if 'ì„±ëª…' in clean or 'ì´ë¦„' in clean: best_match = 'insured_name'
                elif 'ì—°ë½ì²˜' in clean or 'íœ´ëŒ€í°' in clean: best_match = 'insured_phone'
                elif 'ì£¼ë¯¼' in clean: best_match = 'insured_rrn'
                else: best_match = 'insured_name'
            
            # [Step 2] ê³„ì•½ì(Contractor) ê´€ë ¨ í‚¤ì›Œë“œ ê²€ì‚¬
            elif 'ê³„ì•½ì' in clean or 'contractor' in clean:
                if 'ì„±ëª…' in clean or 'ì´ë¦„' in clean: best_match = 'contractor_name'
                elif 'ì—°ë½ì²˜' in clean or 'íœ´ëŒ€í°' in clean: best_match = 'contractor_phone'
                else: best_match = 'contractor_name'
            
            # [Step 3] ì¼ë°˜ í‚¤ì›Œë“œ ë§¤ì¹­
            else:
                for std_key, kws in full_schema.items():
                    # ì´ë¯¸ íŠ¹ìˆ˜ ì²˜ë¦¬ëœ í‚¤ëŠ” ì œì™¸
                    if std_key in ['insured_name','insured_phone','insured_rrn','contractor_name','contractor_phone']: continue
                    for k in kws:
                        if self._clean_text(k) in clean:
                            best_match = std_key; break
                    if best_match: break
            
            if best_match:
                # âœ… [ë°ì´í„°(dbí¬í•¨) ì˜¤ë¥˜] ë™ì¼ í‘œì¤€í‚¤ë¡œ ì¤‘ë³µ ë§¤í•‘ ë°©ì§€
                # - ì—‘ì…€ì— 'ì—°ë½ì²˜'ì™€ 'íœ´ëŒ€ì „í™”'ê°€ í•¨ê»˜ ìˆëŠ” ê²½ìš° ë‘˜ ë‹¤ common_phoneìœ¼ë¡œ ë§¤í•‘ë˜ë©°,
                #   rename ì´í›„ ë™ì¼ ì»¬ëŸ¼ëª…ì´ ì¤‘ë³µë˜ì–´ to_dict() ë‹¨ê³„ì—ì„œ ë’¤ ì»¬ëŸ¼ì´ ì• ì»¬ëŸ¼ì„ ë®ì–´ì“¸ ìˆ˜ ìˆìŒ
                # - ì •ì±…: ìµœì´ˆ ë§¤í•‘(common_phone)ì€ ìœ ì§€í•˜ê³ , ì¶”ê°€ phone ê³„ì—´ì€ company_phoneìœ¼ë¡œ ìš°íšŒ ì €ì¥(ê°€ëŠ¥í•˜ë©´)
                if best_match in mapping.values():
                    if best_match == 'common_phone' and ('company_phone' not in mapping.values()):
                        mapping[user_col] = 'company_phone'
                    else:
                        continue
                else:
                    mapping[user_col] = best_match

        return mapping

    def _parse_rrn(self, rrn):
        """
        [ì•Œê³ ë¦¬ì¦˜: ê°œì¸ì •ë³´ ë³´í˜¸ íŒŒì‹±]
        ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸(13ìë¦¬)ë¥¼ ì…ë ¥ë°›ì•„ ìƒë…„ì›”ì¼ê³¼ ì„±ë³„ë§Œ ì¶”ì¶œí•˜ê³ ,
        ì›ë³¸ ì£¼ë¯¼ë²ˆí˜¸ëŠ” ë°˜í™˜í•˜ì§€ ì•ŠìŒìœ¼ë¡œì¨ DB ì €ì¥ ìì²´ë¥¼ ì›ì²œ ì°¨ë‹¨í•¨.
        """
        if pd.isna(rrn): return None, None
        nums = re.sub(r'[^0-9]', '', str(rrn))
        if len(nums) < 7: return None, None # 7ìë¦¬(ìƒë…„ì›”ì¼+ì„±ë³„ì½”ë“œ)ë§Œ ìˆì–´ë„ ì²˜ë¦¬ ê°€ëŠ¥
        try:
            front = nums[:6]; g_code = int(nums[6])
            # 2000ë…„ëŒ€ìƒ êµ¬ë¶„ ë¡œì§
            if g_code in [1, 2, 5, 6]: y_pre = "19"
            elif g_code in [3, 4, 7, 8]: y_pre = "20"
            else: return None, None
            birth = f"{y_pre}{front[:2]}-{front[2:4]}-{front[4:6]}"
            gender = "ë‚¨" if g_code % 2 else "ì—¬"
            return birth, gender
        except: return None, None

    def _clean_phone(self, val):
        """ì „í™”ë²ˆí˜¸ í¬ë§· í†µì¼ (010-XXXX-XXXX)"""
        if pd.isna(val): return None
        s = re.sub(r'[^0-9]', '', str(val))
        if len(s) == 11 and s.startswith('010'): return f"{s[:3]}-{s[3:7]}-{s[7:]}"
        return str(val)

    def process(self, df):
        """
        [ETL ì‹¤í–‰ ë©”ì¸ í”„ë¡œì„¸ìŠ¤]
        ê¸°ëŠ¥: 
        1. í—¤ë” ì •ê·œí™”
        2. í–‰ ë‹¨ìœ„ ë°ì´í„° ë¶„í•´ (ì¸ì ì‚¬í•­ / ê³„ì•½ì •ë³´ / ì»¤ìŠ¤í…€ì •ë³´)
        3. ë°ì´í„° íƒ€ì… ë³€í™˜ ë° ì •ì œ
        """
        header_map = self._normalize_header(df.columns)
        df_renamed = df.rename(columns=header_map)
        # [â˜…ê¸´ê¸‰ ìˆ˜ì •] ì¤‘ë³µ ì»¬ëŸ¼ ì œê±° ë¡œì§ ì¶”ê°€
        # ì›ì¸: ì—‘ì…€ì˜ 'íœ´ëŒ€í°'ê³¼ 'H.P'ê°€ ë‘˜ ë‹¤ 'phone'ìœ¼ë¡œ ë§¤í•‘ë˜ë©´, 
        #       row['phone'] í˜¸ì¶œ ì‹œ ê°’ì´ 2ê°œê°€ ë˜ì–´ ì—ëŸ¬(Ambiguous) ë°œìƒ.
        # í•´ê²°: ì¤‘ë³µëœ ì»¬ëŸ¼ëª…ì´ ìˆë‹¤ë©´ ì²« ë²ˆì§¸ ê²ƒë§Œ ë‚¨ê¸°ê³  ì œê±°í•¨.
        df_renamed = df_renamed.loc[:, ~df_renamed.columns.duplicated()]


        processed_data = []

        for _, row in df_renamed.iterrows():
            row_data = {}; contract_json = {}; custom_json = {}

            # 1. ê³ ê° ì‹ë³„ì ì¶”ì¶œ (ê³„ì•½ì ìš°ì„  ì •ì±…)
            final_name = row.get('contractor_name') if pd.notna(row.get('contractor_name')) else row.get('common_name')
            if pd.isna(final_name): continue # ì´ë¦„ ì—†ìœ¼ë©´ ìœ íš¨í•˜ì§€ ì•Šì€ ë°ì´í„°
            row_data['name'] = final_name

            # 2. ì—°ë½ì²˜ ì •ì œ
            final_phone = row.get('contractor_phone') if pd.notna(row.get('contractor_phone')) else row.get('common_phone')
            row_data['phone'] = self._clean_phone(final_phone)

            # 3. ë¯¼ê°ì •ë³´(ì£¼ë¯¼ë²ˆí˜¸) ì•ˆì „ ë³€í™˜
            b_rrn, g_rrn = self._parse_rrn(row.get('rrn'))
            row_data['birth_date'] = b_rrn if b_rrn else row.get('birth_date')
            row_data['gender'] = g_rrn if g_rrn else row.get('gender')

            # 4. ê¸°íƒ€ ì¸ì ì‚¬í•­ ë§¤í•‘
            for col in ['region', 'email']:
                if col in df_renamed.columns: row_data[col] = row[col]

            # 5. ê³„ì•½ ì •ë³´ ë° í”¼ë³´í—˜ì ìƒì„¸ ì¶”ì¶œ (ë³„ë„ JSON ê°ì²´ë¡œ ë¶„ë¦¬)
            i_name = row.get('insured_name')
            i_phone = row.get('insured_phone')
            i_rrn = row.get('insured_rrn')

            if pd.notna(i_name):
                contract_json['insured_name'] = str(i_name)
                if pd.notna(i_phone): contract_json['insured_phone'] = self._clean_phone(i_phone)
                # í”¼ë³´í—˜ì ì£¼ë¯¼ë²ˆí˜¸ë„ ì•ˆì „í•˜ê²Œ ìƒì¼/ì„±ë³„ë¡œë§Œ ë³€í™˜
                ib, ig = self._parse_rrn(i_rrn)
                if ib: contract_json['insured_birth'] = ib
                if ig: contract_json['insured_gender'] = ig
                
                # [íŠ¹í—ˆ í¬ì¸íŠ¸: ê°€ì¡± ê´€ê³„ ì¶”ë¡ ]
                # ê³„ì•½ìì™€ í”¼ë³´í—˜ìê°€ ë‹¤ë¥¼ ê²½ìš°, ê°€ì¡±ì¼ í™•ë¥ ì´ ë†’ìœ¼ë¯€ë¡œ íŒíŠ¸ ë°ì´í„° ìƒì„±
                if final_name != i_name:
                    custom_json['family_relation_guess'] = f"í”¼ë³´í—˜ì: {i_name}"

            # ê¸ˆìœµ ë°ì´í„° ë§¤í•‘
            for key in ['company', 'product_name', 'policy_no', 'premium', 'status', 'start_date', 'end_date']:
                if key in df_renamed.columns and pd.notna(row[key]):
                    contract_json[key] = str(row[key])

            # 6. ë¯¸ë§¤í•‘ ë°ì´í„° ì²˜ë¦¬ (ë¹„ì •í˜• ë°ì´í„° ë³´ì¡´)
            std_keys = list(self.identity_map.keys()) + list(self.financial_map.keys())
            for col in df_renamed.columns:
                if col not in std_keys and pd.notna(row[col]):
                    custom_json[col] = str(row[col])

            # 7. ìµœì¢… ë°ì´í„° ì¡°ë¦½
            if custom_json: row_data['custom_data'] = json.dumps(custom_json, ensure_ascii=False)
            if contract_json:
                # v5: financial(í‘œì¤€) + financial_temp(í˜¸í™˜)
                row_data['financial'] = contract_json
                row_data['financial_temp'] = contract_json 

            processed_data.append(row_data)
        
        return pd.DataFrame(processed_data)

# ---------------------------------------------------------
# [NEW] íŠ¹í—ˆ í¬ì¸íŠ¸: ì •ë°€ íŒ¨í„´ ëŒ€ì¡° í•¨ìˆ˜
# ---------------------------------------------------------
def is_name_match(real_name: str, masked_input: str) -> bool:
    """
    [íŠ¹í—ˆ í¬ì¸íŠ¸: ë§ˆìŠ¤í‚¹ ë°ì´í„° ì •ë°€ ëŒ€ì¡° ì•Œê³ ë¦¬ì¦˜]
    ì‹¤ëª…(í™ê¸¸ë™)ê³¼ ë§ˆìŠ¤í‚¹ëœ ì…ë ¥(í™*ë™)ì´ ë…¼ë¦¬ì ìœ¼ë¡œ ì¼ì¹˜í•˜ëŠ”ì§€ ê¸€ì ë‹¨ìœ„ë¡œ ê²€ì¦.
    """
    if not real_name or not masked_input: return False
    
    r_clean = str(real_name).strip()
    m_clean = str(masked_input).strip()
    
    if len(r_clean) != len(m_clean): return False
        
    for r_char, m_char in zip(r_clean, m_clean):
        # ë§ˆìŠ¤í‚¹ ë¬¸ì(*, ?, X)ëŠ” ë¬´ì¡°ê±´ í†µê³¼ (Wildcard)
        if m_char in ['*', '?', 'X', 'x']:
            continue
        # ë³´ì´ëŠ” ê¸€ìëŠ” ì •í™•íˆ ì¼ì¹˜í•´ì•¼ í•¨
        if r_char != m_char:
            return False
    return True


# =========================================================
# [Date Formatting Helpers] Patch (Final)
#  - ìƒì¼/ì²­ì•½: "MM.DD(n)" í‘œê¸°
#  - ì¼ì •: "MM.DD HH:MM" í‘œê¸° + D- / D+ í‘œê¸°
# =========================================================
from datetime import datetime, date
from typing import Optional

def _parse_date_any(x) -> Optional[date]:
    if x is None:
        return None
    if isinstance(x, datetime):
        return x.date()
    if isinstance(x, date):
        return x
    s = str(x).strip()
    if not s:
        return None
    # ISO ìš°ì„ 
    try:
        return datetime.fromisoformat(s[:10]).date()
    except Exception:
        pass
    for fmt in ("%Y-%m-%d", "%Y.%m.%d", "%Y/%m/%d"):
        try:
            return datetime.strptime(s[:10], fmt).date()
        except Exception:
            continue
    return None

def _parse_datetime_any(x) -> Optional[datetime]:
    if x is None:
        return None
    if isinstance(x, datetime):
        return x
    if isinstance(x, date):
        return datetime.combine(x, datetime.min.time())
    s = str(x).strip()
    if not s:
        return None
    s2 = s.replace(".", "-").replace("/", "-")
    # seconds ì—†ëŠ” ì¼€ì´ìŠ¤ ë³´ì •
    if len(s2) == 16 and s2[10] == " ":
        cands = (s2, s2 + ":00")
    else:
        cands = (s2,)
    for cand in cands:
        try:
            return datetime.fromisoformat(cand)
        except Exception:
            pass
    # ë§ˆì§€ë§‰ fallback
    for fmt in ("%Y-%m-%d %H:%M:%S", "%Y-%m-%d %H:%M", "%Y-%m-%d"):
        try:
            return datetime.strptime(s2[:len(fmt)], fmt)
        except Exception:
            continue
    return None

def fmt_mmdd_paren(date_or_str, n=None) -> str:
    """MM.DD ë˜ëŠ” MM.DD(n)"""
    d = _parse_date_any(date_or_str)
    if not d:
        return "-"
    mmdd = f"{d.month:02d}.{d.day:02d}"
    if n is None:
        return mmdd
    try:
        return f"{mmdd}({int(n)})"
    except Exception:
        return mmdd

def fmt_mmdd_hhmm(dt_or_str) -> str:
    """MM.DD HH:MM (ì‹œê°„ì´ ì—†ìœ¼ë©´ MM.DD)"""
    dt = _parse_datetime_any(dt_or_str)
    if not dt:
        return "-"
    raw = str(dt_or_str).strip() if dt_or_str is not None else ""
    if len(raw) <= 10:
        return f"{dt.month:02d}.{dt.day:02d}"
    return f"{dt.month:02d}.{dt.day:02d} {dt.hour:02d}:{dt.minute:02d}"

def calc_age_on(birth_date, on_date) -> Optional[int]:
    """on_date ê¸°ì¤€ ë§Œ ë‚˜ì´(ë‹¨ìˆœ ì—°ë„ì°¨ - ìƒì¼ ì—¬ë¶€ ë°˜ì˜)"""
    bd = _parse_date_any(birth_date)
    od = _parse_date_any(on_date)
    if not bd or not od:
        return None
    age = od.year - bd.year
    if (od.month, od.day) < (bd.month, bd.day):
        age -= 1
    return int(age)

def fmt_dday(dt_or_str) -> str:
    """
    ê¸°ì¤€: ì˜¤ëŠ˜(ë‚ ì§œ) ëŒ€ë¹„
      - ë¯¸ë˜: D-3
      - ì˜¤ëŠ˜: D-0
      - ê³¼ê±°(ì—°ì²´): D+2
    """
    dt = _parse_datetime_any(dt_or_str)
    if not dt:
        return "D-?"
    today = date.today()
    diff = (dt.date() - today).days
    if diff >= 0:
        return f"D-{diff}"
    return f"D+{abs(diff)}"


# ---------------------------------------------------------
# [ë°ì´í„°(dbí¬í•¨) ì˜¤ë¥˜] (CTO Patch Pack v2025-12-22)
# ëª©ì :
# 1) Streamlit 2025-12-31 ì´í›„ ì œê±° ì˜ˆì •(use_container_width) íŒŒë¼ë¯¸í„°ë¥¼
#    ì½”ë“œ(UI) ìˆ˜ì • ì—†ì´ë„ ì•ˆì „í•˜ê²Œ ë™ì‘ì‹œí‚¤ê¸° ìœ„í•œ "í˜¸í™˜ ë ˆì´ì–´" ì œê³µ
#    - use_container_width=True  -> width="stretch"
#    - use_container_width=False -> width="content"
# 2) Streamlit DataFrame ë Œë”ë§ ì‹œ PyArrow ì§ë ¬í™” ì‹¤íŒ¨(ArrowTypeError) ë°©ì§€
#    - íŠ¹íˆ pandas.DataFrame ë‚´ datetime.time ê°ì²´(ì—‘ì…€ 'ì‹œê°„' ì„œì‹)ë¡œ ì¸í•œ ì˜¤ë¥˜ë¥¼
#      ì‚¬ì „ ì •ê·œí™”í•˜ì—¬ ë¯¸ë¦¬ë³´ê¸°/í¸ì§‘/í…Œì´ë¸” ì¶œë ¥ì´ "í•­ìƒ" ì„±ê³µí•˜ë„ë¡ ë³´ì¥
#
# íŠ¹í—ˆ í¬ì¸íŠ¸(ëª…ì„¸ì„œ/ì‹¤ì‹œì˜ˆ ê¸°ì¬ìš©):
# - (ê¸°ìˆ ì  ê³¼ì œ) ì™¸ë¶€ ì…ë ¥(ì—‘ì…€/CSV)ì—ì„œ ë°œìƒí•˜ëŠ” ë¹„ì •í˜• íƒ€ì…(datetime.time ë“±)ìœ¼ë¡œ ì¸í•´
#   UI ê³„ì¸µì˜ ì§ë ¬í™”(Arrow) ì‹¤íŒ¨ â†’ ì—…ë¡œë“œ ë¯¸ë¦¬ë³´ê¸° ë‹¨ê³„ì—ì„œ ì‚¬ìš©ì ì‹ ë¢°ë„ í•˜ë½ ë°
#   ë°ì´í„° ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì¤‘ë‹¨ ê°€ëŠ¥.
# - (í•´ê²° ìˆ˜ë‹¨) (a) ì…ë ¥ ë‹¨ê³„(pandas read_*)ì—ì„œ íƒ€ì… ì •ê·œí™”,
#              (b) í‘œì‹œ ë‹¨ê³„(streamlit dataframe/editor)ì—ì„œ 2ì°¨ ì •ê·œí™”,
#              (c) íê¸° ì˜ˆì • API(use_container_width)ì— ëŒ€í•œ ëŸ°íƒ€ì„ í˜¸í™˜ ë ˆì´ì–´ ì œê³µ.
# - (ê¸°ìˆ ì  íš¨ê³¼) (1) UI ë Œë”ë§ ì‹¤íŒ¨ìœ¨ ê°ì†Œ, (2) ë¡œê·¸/ê²½ê³  ê°ì†Œë¡œ ë°ëª¨ ì‹ ë¢°ë„ í–¥ìƒ,
#               (3) í–¥í›„ Streamlit ë²„ì „ ì—…ë°ì´íŠ¸ ì‹œì—ë„ UI ì½”ë“œ ë³€ê²½ ì—†ì´ ì•ˆì • ë™ì‘.
# ---------------------------------------------------------

import datetime as _dt
import decimal as _dec
from typing import Any as _Any, Callable as _Callable

# ---- Arrow-safe ë³€í™˜ê¸° ----------------------------------------------------
def _kfit_arrow_safe_value(v: _Any) -> _Any:
    """
    pandas -> pyarrow ì§ë ¬í™” ì‹¤íŒ¨ë¥¼ ìœ ë°œí•˜ëŠ” ëŒ€í‘œ ê°ì²´ë¥¼ ë¬¸ìì—´ë¡œ ì •ê·œí™”.
    - datetime.time: ArrowTypeError("... cannot be converted ...")ì˜ ì£¼ìš” ì›ì¸
    - (í™•ì¥ ì—¬ì§€) í•„ìš” ì‹œ ë‹¤ë¥¸ ë¹„ì •í˜• ê°ì²´ë„ ê·œì¹™ ê¸°ë°˜ìœ¼ë¡œ ì¶”ê°€ ê°€ëŠ¥
    """
    if isinstance(v, _dt.time):
        # HH:MM:SS (ì› ë°ì´í„°ê°€ 'ì›”' ê°™ì€ ì˜ë¯¸ì˜€ë”ë¼ë„,
        #           ìµœì†Œí•œ ë Œë”ë§/íŒŒì´í”„ë¼ì¸ì„ ê¹¨ì§€ ì•Šë„ë¡ ì•ˆì „í•œ í‘œí˜„ìœ¼ë¡œ ë³´ì¡´)
        return v.strftime("%H:%M:%S")
    # KFIT_ARROW_SAFE_EXTENDED: ë¹„ì •í˜• ê°ì²´(ë¦¬ìŠ¤íŠ¸/ë”•íŠ¸/ì§‘í•©/Decimal/Timedelta ë“±)ë¥¼ ë¬¸ìì—´ë¡œ ì•ˆì „ ë³€í™˜
    try:
        import pandas as _pd
        if isinstance(v, (_pd.Timestamp,)):
            # TimestampëŠ” isoformatìœ¼ë¡œ ì•ˆì „ ì§ë ¬í™”
            return v.isoformat()
    except Exception:
        pass
    if isinstance(v, (_dt.timedelta,)):
        return str(v)
    if isinstance(v, (_dec.Decimal,)):
        return format(v, "f")
    if isinstance(v, (set, tuple)):
        return json.dumps(list(v), ensure_ascii=False)
    if isinstance(v, (dict, list)):
        return json.dumps(v, ensure_ascii=False)

    return v

def _kfit_make_arrow_safe_df(df: "pd.DataFrame") -> "pd.DataFrame":
    """
    DataFrameì„ Arrow-safe í˜•íƒœë¡œ ì •ê·œí™”.
    ì„±ëŠ¥ ê³ ë ¤:
    - object dtype ì»¬ëŸ¼ë§Œ ëŒ€ìƒìœ¼ë¡œ
    - ê° ì»¬ëŸ¼ì˜ dropna().head(50) ìƒ˜í”Œë¡œ time ê°ì²´ ì¡´ì¬ ì—¬ë¶€ë¥¼ í™•ì¸ í›„ ë³€í™˜
    """
    try:
        import pandas as _pd
    except Exception:
        return df

    if not isinstance(df, _pd.DataFrame) or df.empty:
        return df

    # ë³€í™˜ ëŒ€ìƒ ì»¬ëŸ¼ íƒì§€
    cols_to_fix = []
    for c in df.columns:
        try:
            if str(df[c].dtype) != "object":
                continue
            sample = df[c].dropna().head(50).tolist()
            if any(isinstance(x, _dt.time) for x in sample):
                cols_to_fix.append(c)
        except Exception:
            # ì»¬ëŸ¼ ì ‘ê·¼ ì‹¤íŒ¨ ì‹œ ê±´ë„ˆëœ€(ì•ˆì •ì„± ìš°ì„ )
            continue

    if not cols_to_fix:
        return df

    # ì›ë³¸ ë³€í˜•ì„ í”¼í•˜ê¸° ìœ„í•´ ìµœì†Œ ë³µì‚¬(copy-on-writeì™€ ë¬´ê´€í•˜ê²Œ ì•ˆì „í•˜ê²Œ)
    df2 = df.copy()
    for c in cols_to_fix:
        try:
            df2[c] = df2[c].map(_kfit_arrow_safe_value)
        except Exception:
            # map ì‹¤íŒ¨ ì‹œ ë” ê°•í•œ ë³€í™˜(ëŠë¦¬ì§€ë§Œ ì•ˆì „)
            df2[c] = df2[c].apply(_kfit_arrow_safe_value)
    return df2

# ---- pandas ì…ë ¥ ë‹¨ê³„(read_*) ì•ˆì „í™” --------------------------------------
# ì—…ë¡œë“œ ë¯¸ë¦¬ë³´ê¸° ë‹¨ê³„ì—ì„œ ê°€ì¥ ë¨¼ì € í„°ì§€ë¯€ë¡œ, ì…ë ¥ ë‹¨ê³„ì—ì„œ 1ì°¨ë¡œ ì •ê·œí™”í•˜ì—¬
# ì´í›„ ETL/ë¶„ì„/í‘œì‹œ ì „ ê³¼ì •ì˜ íƒ€ì… ì¼ê´€ì„±ì„ í™•ë³´í•œë‹¤.
try:
    import pandas as _pd  # noqa: F401

    _KFIT_ORIG_READ_EXCEL = _pd.read_excel
    _KFIT_ORIG_READ_CSV = _pd.read_csv

    def _kfit_read_excel_safe(*args, **kwargs):
        df = _KFIT_ORIG_READ_EXCEL(*args, **kwargs)
        return _kfit_make_arrow_safe_df(df)

    def _kfit_read_csv_safe(*args, **kwargs):
        df = _KFIT_ORIG_READ_CSV(*args, **kwargs)
        return _kfit_make_arrow_safe_df(df)

    _pd.read_excel = _kfit_read_excel_safe
    _pd.read_csv = _kfit_read_csv_safe
except Exception:
    # pandas import ì‹¤íŒ¨ ë“± ê·¹ë‹¨ ìƒí™©ì—ì„œë„ ì•± ì „ì²´ëŠ” ë™ì‘í•´ì•¼ í•¨
    pass

# ---- Streamlit í˜¸í™˜ ë ˆì´ì–´(use_container_width -> width) ------------------
def _kfit_map_use_container_width(kwargs: dict) -> None:
    """
    Streamlit deprecate ëŒ€ì‘:
      use_container_width=True  -> width="stretch"
      use_container_width=False -> width="content"
    """
    if "use_container_width" in kwargs:
        ucw = kwargs.pop("use_container_width")
        # widthê°€ ì´ë¯¸ ì£¼ì–´ì§„ ê²½ìš°ëŠ” ì¡´ì¤‘
        if "width" not in kwargs:
            kwargs["width"] = "stretch" if bool(ucw) else "content"

def _kfit_wrap_streamlit_fn(fn: _Callable, *, df_arg_name: str | None = None) -> _Callable:
    """
    Streamlit í•¨ìˆ˜ ë˜í¼:
    1) use_container_width ì¸ìë¥¼ widthë¡œ ë³€í™˜ (ê²½ê³ /ë¯¸ë˜ ì˜¤ë¥˜ ë°©ì§€)
    2) dataframe/editor ê³„ì—´ì€ Arrow-safe ë³€í™˜ ì ìš© (ì§ë ¬í™” ì‹¤íŒ¨ ë°©ì§€)
    3) width ë¯¸ì§€ì› ë²„ì „(êµ¬ë²„ì „) ëŒ€ë¹„: TypeError ì‹œ width ì œê±° í›„ ì¬í˜¸ì¶œ
    """
    def _wrapped(*args, **kwargs):
        _kfit_map_use_container_width(kwargs)

        # dataframe/editorì—ëŠ” data ì¸ì ì •ê·œí™”
        if df_arg_name:
            try:
                import pandas as _pd2
                if args:
                    data = args[0]
                    if isinstance(data, _pd2.DataFrame):
                        args = ( _kfit_make_arrow_safe_df(data), ) + tuple(args[1:])
                else:
                    data = kwargs.get(df_arg_name)
                    if isinstance(data, _pd2.DataFrame):
                        kwargs[df_arg_name] = _kfit_make_arrow_safe_df(data)
            except Exception:
                pass

        try:
            return fn(*args, **kwargs)
        except TypeError as e:
            # ì¼ë¶€ ìœ„ì ¯/ë²„ì „ì—ì„œ width ë¯¸ì§€ì›ì¼ ìˆ˜ ìˆìŒ â†’ width ì œê±° í›„ ì¬ì‹œë„
            if "width" in kwargs:
                kw2 = dict(kwargs)
                kw2.pop("width", None)
                return fn(*args, **kw2)
            raise e

    return _wrapped

def _kfit_apply_streamlit_compat() -> None:
    """
    ì•± ì „ì²´ì—ì„œ 1íšŒ ì‹¤í–‰.
    - UI ì½”ë“œë¥¼ 'ì „í˜€' ìˆ˜ì •í•˜ì§€ ì•Šê³ ë„ ê²½ê³  ì œê±° + ë¯¸ë˜ ë²„ì „ í˜¸í™˜ì„± í™•ë³´.
    """
    try:
        import streamlit as _st
    except Exception:
        return

    # ì´ë¯¸ ì ìš©ëœ ê²½ìš° ì¤‘ë³µ ë˜í•‘ ë°©ì§€(ì•ˆì „)
    if getattr(_st, "_kfit_compat_applied", False):
        return
    _st._kfit_compat_applied = True

    # ë˜í•‘ ëŒ€ìƒ(í˜„ì¬ ì½”ë“œë² ì´ìŠ¤ì—ì„œ use_container_width ì‚¬ìš© ë¹ˆë„ê°€ ë†’ì€ í•¨ìˆ˜ë“¤)
    _st.dataframe = _kfit_wrap_streamlit_fn(_st.dataframe, df_arg_name="data")
    _st.data_editor = _kfit_wrap_streamlit_fn(_st.data_editor, df_arg_name="data")
    _st.button = _kfit_wrap_streamlit_fn(_st.button)
    _st.download_button = _kfit_wrap_streamlit_fn(_st.download_button)
    _st.form_submit_button = _kfit_wrap_streamlit_fn(_st.form_submit_button)

# utils ëª¨ë“ˆ import ì‹œì ì— ìë™ ì ìš©(ë©”ì¸/í•˜ìœ„ ëª¨ë“ˆ ì–´ë””ì—ì„œë“  ë™ì¼ íš¨ê³¼)
_kfit_apply_streamlit_compat()

# ---- (ì½”ë“œë¸”ë¡ ë í‘œê¸° ìš”êµ¬ ëŒ€ì‘) ------------------------------------------
# ìˆ˜ì • ì „/í›„ ì¤„ìˆ˜ ë° ì²´í¬ë¦¬ìŠ¤íŠ¸ëŠ” íŒŒì¼ ë§ë¯¸ì— ìë™ ê¸°ì…ë©ë‹ˆë‹¤.
# ---------------------------------------------------------

# ---------------------------------------------------------
# [ì²´í¬ë¦¬ìŠ¤íŠ¸]
# - UI ìœ ì§€/ì¡´ì¹˜: âœ… ìœ ì§€ë¨
# - ìˆ˜ì • ë²”ìœ„: âœ… ë³€ê²½ ì—†ìŒ(ê¸°ì¡´ ìœ ì§€)
# - '..., ì¤‘ëµ, ì¼ë¶€ ìƒëµ' ê¸ˆì§€: âœ… ì¤€ìˆ˜(ì „ì²´ íŒŒì¼ ìœ ì§€)
# - ìˆ˜ì • ì „ ë¼ì¸ìˆ˜: 753
# - ìˆ˜ì • í›„ ë¼ì¸ìˆ˜: 753 (+0)
# ---------------------------------------------------------
